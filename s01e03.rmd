---
title: SLICED s01e03
author: Jo Dudding
output: 
  html_document:
    theme: united
    highlight: kate
    toc: true
    toc_float: 
      collapsed: true
    includes:
      in_header: "header.html"
---

```{r setup, include = FALSE, echo = FALSE}
#-------------------------------------------------------------------------------
#' set knitr options
#-------------------------------------------------------------------------------

knitr::opts_chunk$set(
  fig.width = 24 / 2.54,
  fig.height = 13.4 / 2.54,
  fig.retina = 4,
  comment = '',
  warning = FALSE
)
```

```{css, echo = FALSE}
h1, h2, h3, h4, h5, h6, legend {
  color: #302df0;
}

h1.title {
    font-size: 38px;
    background-color: #e946a5;
    color: #ffffff;
    margin-bottom: 20px;
    padding: 9.5px;
    padding-top: 20px;
    padding-bottom: 20px;
    border-radius: 10px;
}

pre {
  background-color: #cccccc;
}

a {
  color: #129875;
}

.hljs-comment {
    color: #68e199;
    font-style: 68e199;
}

.list-group-item.active, .list-group-item.active:hover, .list-group-item.active:focus {
    z-index: 2;
    color: #ffffff;
    background-color: #68e199;
    border-color: #68e199;
}
```

Predict Super Store profit

[Kaggle link](https://www.kaggle.com/c/sliced-s01e03-DcSXes/overview)

[Twitch link](https://www.twitch.tv/nickwan_datasci)

The evaluation measure for this competition is RMSE.

# Load libraries

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(tidymodels)
library(scales)
library(skimr)
library(kableExtra)
library(patchwork)
library(gt)
library(lubridate)
library(glue)
library(themis)
library(credentials)
library(usemodels)
```


# My settings

```{r}

# colours
#pal_jo <- c(viridisLite::magma(8)[2:8], "#4C4C53", "#9B9BA8")

pal_sliced <- c(
  '#e946a5', # pink
  '#68e199', # green
  '#302df0', # blue
  '#6a45b0', # purple
  '#129875', # darker green
  '#4f94bf', # lighter blue
  '#b545ab', # darker pink
  '#000000', # black,
  '#cccccc'  #grey
)

title_colour <- pal_sliced[1]
table_colour <- pal_sliced[4]
bar_colour <- pal_sliced[2]
grid_colour <- pal_sliced[9]

theme_set(theme_bw() %+replace%
    theme(
      # align title and caption to the plot not the panel
      plot.title.position = 'plot',
      plot.caption.position = 'plot',
      # change the title and caption to markdown and move them futher from the plot
      plot.title = element_text(
        size = rel(1.3),
        hjust = 0, 
        margin = margin(c(0, 0, 10, 0)),
        colour = title_colour
      ),
      plot.subtitle = element_text(
        size = rel(1.15),
        hjust = 0, 
        margin = margin(c(0, 0, 15, 0))
      ),
      plot.caption = element_text(
        hjust = 1, 
        margin = margin(c(10, 0, 0, 0))
      ),
      # move axis titles to the left/top and change them to markdown
      axis.title = element_text(hjust = 1),
      # allow the axis values to the markdown as well
      axis.text = element_text(),
      # remove the panel border
      panel.border = element_blank(),
      # put in the axis lines with a slightly thicker line than the gridlines
      axis.line = element_line(colour = grid_colour, size = rel(1.5)),
      # make the tickmarks the same colour
      axis.ticks = element_line(colour = grid_colour),
      # facet strip text left aligned with extra space above
      strip.text = element_text(
        hjust = 0, margin = margin(c(10, 0, 0, 0)), colour = title_colour
      ),
      # clear colour and fill for strip
      strip.background = element_rect(colour = NA, fill = NA),
      # dotted gridlines
      panel.grid = element_line(linetype = 'dotted'),
      # ability to use a different colour for the gridlines
      panel.grid.major.x = element_line(colour = grid_colour),
      panel.grid.major.y = element_line(colour = grid_colour),
      panel.grid.minor.x = element_blank(),
      panel.grid.minor.y = element_blank(),
    )
)

scale_y_pct <- function(
  accuracy = 1L, 
  breaks = pretty_breaks(),
  expand = expansion(mult = c(0, .05)),
  ...
) {
  scale_y_continuous(
    labels = scales::percent_format(accuracy = accuracy, big.mark = ","),
    breaks = breaks,
    expand = expand,
    ...
  )
}

scale_y_comma <- function(
  accuracy = 1L, 
  breaks = pretty_breaks(),
  expand = expansion(mult = c(0, .05)),
  ...
) {
  scale_y_continuous(
    labels = scales::comma_format(accuracy = accuracy),
    breaks = breaks,
    expand = expand,
    ...
  )
}

scale_fill_jo <- function(...) {
  scale_fill_manual(values = pal_sliced, ...)
}

scale_fill_discrete <- scale_fill_jo

update_geom_defaults("bar", list(fill = bar_colour))
update_geom_defaults("col", list(fill = bar_colour))
update_geom_defaults("point", list(colour = bar_colour))
update_geom_defaults("line", list(colour = bar_colour))
```


# Read files

```{r}
to_build <- read_csv("s01e03/train.csv", guess_max = 200000) 
to_score <- read_csv("s01e03/test.csv", guess_max = 200000) 
```
# Look at submission file

```{r}
submission <- read_csv("s01e03/sample_submission.csv", guess_max = 200000) %>% 
  glimpse()
```

Submission file contains `id` and estimate of `profit`.  The sample submission estimates 36.22037 as the profit for all rows.  This gives an RMSE of 263.8. `r mean(to_build$profit)` is the mean of the profit in the training data.

# Examine data

```{r}
skim(to_build)
```

## Initial thoughts

- no missing data!
- 7k rows
- country has only one value - omit
- lots of cities
- postcode is numeric - should be character, but can be omitted I think.
- can we calculate something useful from discount, sales and quantity
- are the states in the holdout data different?
- could potentially bring in external data of city size or median income, etc.

```{r}
build_state <- to_build %>% 
  count(state, sort = TRUE) %>% 
  rename(n_build = n)

score_state <- to_score %>% 
  count(state, sort = TRUE)%>% 
  rename(n_score = n)

build_state %>% 
  full_join(score_state, by = 'state') %>% 
  count(
    `Missing state in training` = is.na(n_build), 
    `Missing state in holdout` = is.na(n_score)
  ) %>% 
  gt()

```

Yes, they are different, so we can't use city or state.

# Split in to train and test

```{r}
set.seed(505)

split <- initial_split(to_build, strata = profit)
train <- training(split)
test <- testing(split)
```

# Create folds

```{r}
set.seed(506)
train_folds <- vfold_cv(train, 5)
```

# Get workflow template

```{r}
use_xgboost(profit ~ ., data = train)
```

# Create recipe

```{r}
xgboost_recipe <- 
  recipe(formula = profit ~ ., data = train) %>% 
  # id role
  update_role(id, new_role = "ID") %>%
  # remove unneeded
  step_rm(country, postal_code, city, state) %>% 
  step_string2factor(ship_mode, segment, region, category, sub_category) %>% 
  step_novel(all_nominal(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>% 
  step_zv(all_predictors()) 
```

# Check recipe outputs

```{r}
prepped <- prep(xgboost_recipe)
baked <- bake(prepped, new_data = NULL) 

skim(baked)
```

# Create model specification

Let's start with something simple.  No tuning at this stage.

```{r}
xgboost_spec <- 
  boost_tree(trees = 1000) %>% 
  set_mode("regression") %>% 
  set_engine("xgboost") 
```

# Create workflow

```{r}
xgboost_workflow <- 
  workflow() %>% 
  add_recipe(xgboost_recipe) %>% 
  add_model(xgboost_spec) 

```

# Fit model

```{r}
xgboost_fit <- last_fit(xgboost_workflow, split, metric = "rmse")
```

# Check performance

```{r}
collect_metrics(xgboost_fit, metric = "rmse") %>%
  gt()
```


# Get predictions

```{r}
xgboost_preds <- collect_predictions(xgboost_fit)

xgboost_preds %>%
  ggplot(aes(profit, .pred)) +
  geom_abline(lty = 2, colour = pal_sliced[3]) +
  geom_point(alpha = 0.5) +
  coord_fixed() +
  labs(title = 'Predicted vs actual')
```

# Apply to new data

```{r}
have_scored <- cbind(to_score, predict(xgboost_fit$.workflow[[1]], to_score)) %>%
  select(id, profit = .pred)
```

# Output submission

```{r}
write_csv(have_scored, 's01e03/submission.csv')
```

# Outcome

Submitting this to Kaggle gives me a score of 16.60, which puts me at the top of the leaderboard (first place is 116.92).  Probably because I figured out the state thing.

# Learnings

- Read the data page of the competition - *The test set (test.csv) is a holdout of several states' orders.*
- Make sure the train and holdout data are similar
- Start with something simple, and go back and refine if necessary