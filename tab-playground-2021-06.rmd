---
title: Tabular Playground - June 2021
author: Jo Dudding
output: 
  html_document:
    theme: united
    highlight: kate
    toc: true
    toc_float: 
      collapsed: true
    includes:
      in_header: "header.html"
---

```{r setup, include = FALSE, echo = FALSE}
#-------------------------------------------------------------------------------
#' set knitr options
#-------------------------------------------------------------------------------

knitr::opts_chunk$set(
  fig.width = 24 / 2.54,
  fig.height = 13.4 / 2.54,
  fig.retina = 4,
  comment = '',
  warning = FALSE
)
```

```{css, echo = FALSE}
h1, h2, h3, h4, h5, h6, legend {
  color: #302df0;
}

h1.title {
    font-size: 38px;
    background-color: #e946a5;
    color: #ffffff;
    margin-bottom: 20px;
    padding: 9.5px;
    padding-top: 20px;
    padding-bottom: 20px;
    border-radius: 10px;
}

pre {
  background-color: #cccccc;
}

a {
  color: #129875;
}

.hljs-comment {
    color: #68e199;
    font-style: 68e199;
}

.list-group-item.active, .list-group-item.active:hover, .list-group-item.active:focus {
    z-index: 2;
    color: #ffffff;
    background-color: #68e199;
    border-color: #68e199;
}
```

Predict Super Store profit

[Kaggle link](https://www.kaggle.com/c/sliced-s01e03-DcSXes/overview)

[Twitch link](https://www.twitch.tv/nickwan_datasci)

The evaluation measure for this competition is RMSE.

# Load libraries

```{r, message = FALSE, warning = FALSE}
library(tidyverse)
library(tidymodels)
library(scales)
library(skimr)
library(kableExtra)
library(patchwork)
library(gt)
library(lubridate)
library(glue)
library(themis)
library(usemodels)
```


# My settings

```{r}

# colours
#pal_jo <- c(viridisLite::magma(8)[2:8], "#4C4C53", "#9B9BA8")

pal_sliced <- c(
  '#e946a5', # pink
  '#68e199', # green
  '#302df0', # blue
  '#6a45b0', # purple
  '#129875', # darker green
  '#4f94bf', # lighter blue
  '#b545ab', # darker pink
  '#000000', # black,
  '#cccccc'  #grey
)

title_colour <- pal_sliced[1]
table_colour <- pal_sliced[4]
bar_colour <- pal_sliced[2]
grid_colour <- pal_sliced[9]

theme_set(theme_bw() %+replace%
    theme(
      # align title and caption to the plot not the panel
      plot.title.position = 'plot',
      plot.caption.position = 'plot',
      # change the title and caption to markdown and move them futher from the plot
      plot.title = element_text(
        size = rel(1.3),
        hjust = 0, 
        margin = margin(c(0, 0, 10, 0)),
        colour = title_colour
      ),
      plot.subtitle = element_text(
        size = rel(1.15),
        hjust = 0, 
        margin = margin(c(0, 0, 15, 0))
      ),
      plot.caption = element_text(
        hjust = 1, 
        margin = margin(c(10, 0, 0, 0))
      ),
      # move axis titles to the left/top and change them to markdown
      axis.title = element_text(hjust = 1),
      # allow the axis values to the markdown as well
      axis.text = element_text(),
      # remove the panel border
      panel.border = element_blank(),
      # put in the axis lines with a slightly thicker line than the gridlines
      axis.line = element_line(colour = grid_colour, size = rel(1.5)),
      # make the tickmarks the same colour
      axis.ticks = element_line(colour = grid_colour),
      # facet strip text left aligned with extra space above
      strip.text = element_text(
        hjust = 0, margin = margin(c(10, 0, 0, 0)), colour = title_colour
      ),
      # clear colour and fill for strip
      strip.background = element_rect(colour = NA, fill = NA),
      # dotted gridlines
      panel.grid = element_line(linetype = 'dotted'),
      # ability to use a different colour for the gridlines
      panel.grid.major.x = element_line(colour = grid_colour),
      panel.grid.major.y = element_line(colour = grid_colour),
      panel.grid.minor.x = element_blank(),
      panel.grid.minor.y = element_blank(),
    )
)

scale_y_pct <- function(
  accuracy = 1L, 
  breaks = pretty_breaks(),
  expand = expansion(mult = c(0, .05)),
  ...
) {
  scale_y_continuous(
    labels = scales::percent_format(accuracy = accuracy, big.mark = ","),
    breaks = breaks,
    expand = expand,
    ...
  )
}

scale_y_comma <- function(
  accuracy = 1L, 
  breaks = pretty_breaks(),
  expand = expansion(mult = c(0, .05)),
  ...
) {
  scale_y_continuous(
    labels = scales::comma_format(accuracy = accuracy),
    breaks = breaks,
    expand = expand,
    ...
  )
}

scale_fill_jo <- function(...) {
  scale_fill_manual(values = pal_sliced, ...)
}

scale_fill_discrete <- scale_fill_jo

update_geom_defaults("bar", list(fill = bar_colour))
update_geom_defaults("col", list(fill = bar_colour))
update_geom_defaults("point", list(colour = bar_colour))
update_geom_defaults("line", list(colour = bar_colour))
```


# Read files

```{r}
to_build <- read_csv("tab-playground-2021-06/train.csv", guess_max = 200000) %>% 
  # sample of 15% to make it run faster
  slice_sample(prop = .15) %>% 
  mutate(target = factor(target)) %>% 
  glimpse()

to_score <- read_csv("tab-playground-2021-06/test.csv", guess_max = 200000) %>% 
  glimpse()
```

# Look at submission file

```{r}
submission <- read_csv("tab-playground-2021-06/sample_submission.csv", guess_max = 200000) %>% 
  glimpse()
```

# Create basic submission file

Let's put in a first entry with the average proportions.

```{r}
class_percent <- to_build %>% 
  filter(!is.na(target)) %>% 
  count(target) %>% 
  mutate(pct = n / sum(n))

gt(class_percent)
```

```{r}
wide_percent <- class_percent %>% 
  select(-n) %>% 
  mutate(dummy = 1) %>% 
  spread(key = target, value = pct)

basic_score <- to_score %>% 
  select(id) %>% 
  mutate(dummy = 1) %>% 
  left_join(wide_percent, by = 'dummy') %>% 
  select(-dummy) %>% 
  glimpse()
  

```

# Output basic submission

```{r}
write_csv(basic_score, 'tab-playground-2021-06/submission.csv')
```

This gives a score of 1.89555 on the public leaderboard.  The top scorers are around 1.74.

Evaluation is multi-class logarithmic loss (`mn_log_loss`).


# Explore data

```{r}
skim(to_build)
```

## Initial thoughts

- all features are numeric
- most are skewed - > 50% zeros for most, transformation?
- whole numbers?
- mean is between 0 and 3 for most

## Let's look at an example feature

```{r}
to_build %>% 
  ggplot(aes(feature_58)) +
  geom_histogram(binwidth = 1)

to_build %>% 
  ggplot(aes(feature_58, fill = target)) +
  geom_histogram(binwidth = 1, position = 'fill')
```

Let's bucket the higher values.

```{r}
to_build %>% 
  mutate(
    target = fct_infreq(target),
    feature_58_f = cut(feature_58, c(-Inf, 0, 1, 2, 5, 10, Inf))
  ) %>% 
  ggplot(aes(feature_58_f, fill = target)) +
  geom_bar()

to_build %>% 
  mutate(
    target = fct_infreq(target),
    feature_58_f = cut(feature_58, c(-Inf, 0, 1, 2, 5, 10, Inf))
  ) %>% 
  ggplot(aes(feature_58_f, fill = target)) +
  geom_bar(position = 'fill')
```

## Ideas

- for later models could look at bucketing the features
- could also see whether some could be removed with step_cor

# Train, test and folds

## Split in to train and test

```{r}
set.seed(369)

split <- to_build %>% 
  initial_split(strata = target)
  
train <- training(split)
test <- testing(split)
```

## Create folds for tuning

```{r}
set.seed(640)
tune_folds <- train %>% 
  #slice_sample(prop = .15) %>% 
  vfold_cv(5)
```

# Create recipe, spec and workflow

## Get workflow template

```{r}
use_xgboost(target ~ ., data = train)
```

## Use default recipe, spec and workflow

```{r}
xgboost_recipe <- 
  recipe(formula = target ~ ., data = train) %>% 
  #step_string2factor(one_of(target)) %>% 
  step_zv(all_predictors()) 

xgboost_spec <- 
  boost_tree(trees = tune(), min_n = tune(), tree_depth = tune(), learn_rate = tune(), 
    loss_reduction = tune(), sample_size = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("xgboost") 

xgboost_workflow <- 
  workflow() %>% 
  add_recipe(xgboost_recipe) %>% 
  add_model(xgboost_spec) 
```

## Check recipe

```{r}
prepped <- prep(xgboost_recipe)
baked <- bake(prepped, new_data = NULL) 

skim(baked)
```


# Tuning

## Tune folds

```{r}

targ_metric = metric_set(mn_log_loss)

set.seed(83195)
xgboost_tune <-
  tune_grid(xgboost_workflow, resamples = tune_folds, grid = 9, metrics = targ_metric)
```

## Tuning outcome

```{r, eval = FALSE}
show_best(xgboost_tune, metric = "targ_metric") %>%
  gt()

autoplot(xgboost_tune) +
  theme_bw()
```

## Finalise worflow with tuning results

```{r}
final_wkflow <- xgboost_workflow #%>%
  finalize_workflow(select_best(xgboost_tune, metric = targ_metric))
  
final_wkflow
```

# Fit model

## Fit workflow to split

```{r}
xgboost_fit <- last_fit(final_wkflow, split, metric = targ_metric)
```

## Metrics for test

```{r}
collect_metrics(xgboost_fit)
```

> Can we do a ROC curve for each class?  What sort of charts should go here?

## Save model

```{r}
model <- xgboost_fit$.workflow[[1]]

saveRDS(model, 'tab-playground-2021-06/model.rds')

```

# Create holdout submission

## Score holdout 

```{r}
have_scored <- cbind(to_score, predict(model, to_score, type = 'prob')) %>%
  select(id, starts_with('.pred')) %>% 
  rename_all(str_remove, '.pred_')
```

## Create csv

```{r}
write_csv(have_scored, 'tab-playground-2021-06/submission2.csv')
```